{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "european-halloween",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "\n",
    "### Overview\n",
    "This homework assignment is divided into two parts: 1) Prediction of HOLC labels and 2) geodemographic clustering \n",
    "\n",
    "### Deliverables: \n",
    "1. Pandas notebook with outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "agreed-ridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\desai\\miniforge3\\envs\\crp4680\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# We are going to start importing the libraries we need\n",
    "# all in one cell. \n",
    "\n",
    "# It is a good practice to keep all the imports in one cell so that\n",
    "# we can easily see what libraries we are using in the notebook.\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "## There is no need to import libraries more than once!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ffcf1",
   "metadata": {},
   "source": [
    "# 1. Predicting HOLC grades\n",
    "In this exercise, you are going to explore some historical Census data and understand its relationships with the Home Owners' Loan Corporation (HOLC) risk maps. These maps were made by the HOLC in the late 1930s-early 1940s for the HOLC to make assessments of neighborhood risk after the HOLC bailed out underwater borrowers who were unable to pay their mortgage loans as a consequence of the Great Depression. Mortgage risk was assessed with all residential neighborhoods being given an A, B, C, or D grade: \n",
    "\n",
    "- A = \"best\"\n",
    "- B = \"still desirable\"\n",
    "- C = \"definitely declining\"\n",
    "- D = \"hazardous\"\n",
    "\n",
    "While these maps have become known as the \"redlining maps\" note that the agency didn't use these maps to make decisions on who/where should get loans. They actually made these maps after loan activities were already over! However, these maps do provide an interesting window into how the real estate industry viewed different neighborhoods, during a period when redlining (by savings and loan banks, the Federal Housing Administration, amongst others) occurred. In 1968, Congress signed the Fair Housing Act of 1968, also known as Title VIII of the Civil Rights Act of 1968, that formally made discrimination by race, sex, color, religion, disability, family status, and national origin illegal. This is considered by many scholars to be the legal end of discriminatory redlining practices (although they still occur, in various ways, to today). \n",
    "\n",
    "There are three time periods to consider when we're thinking about the \"impacts\" of the redlining: \n",
    "- The pre-redlining period: for now, we'll say that is 1930 and any 1930-1940 trends. \n",
    "- The redlining period: 1940 - 1970\n",
    "- The post-redlining period: 1980 - present\n",
    "\n",
    "The overall aim of this study is to understand whether we think there is a relationship between HOLC grades and present-day outcomes in racial outcomes and neighborhood outcomes such as education or median income. The underlying mechanism here might be that HOLC grades led to disinvestment in neighborhoods, which leads to poor conditions, the concentration of poverty, and low opportunities for people who live in that neighborhood. This leads us to test two scenarios: \n",
    "\n",
    "1. Can we use neighborhood conditions to predict historical HOLC grades during the period of redlining? \n",
    "2. Similarly, if we think that grades were also determined by neighborhood socioeconomic and demographic conditions, can we use these to predict HOLC grades? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af11bb",
   "metadata": {},
   "source": [
    "## 1.1 Load in the data\n",
    "The folder `holc_data` can be downloaded [here](https://www.dropbox.com/scl/fo/efovuq4dg9mmrwhtnvak6/AHew7g8n0jqkuxPGpU3lZBQ?rlkey=g7371rzvg8m2duq86hg3jc6nk&dl=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is a version of the data with all the years as separate columns\n",
    "holc_data = gpd.read_file('https://www.dropbox.com/scl/fi/i017f3g4juwtf6rmpijcq/holc_data_1930_2016.geojson?rlkey=scxpkogx5hcj1r1rvdwg297g8&dl=1',driver='GeoJSON')\n",
    "\n",
    "### This is a version of the data with the years concatenated\n",
    "holc_data_v2 = []\n",
    "for y in ['1930','1940','1950','1960','1970','1980','1990','2010', '2016']: \n",
    "    df = gpd.read_file(f'holc_data/holc_overlay_{y}')\n",
    "    df['year'] = y\n",
    "    holc_data_v2.append(df)\n",
    "\n",
    "holc_data_v2= pd.concat(holc_data_v2)[['city','holc_grade','population','white_perc','colored_pe','hispanic_p','other_perc','college_pe','median_inc','unemployed','geometry','year']]\n",
    "\n",
    "holc_data_v2 = holc_data_v2.rename(columns={'colored_pe':'black_perc','hispanic_p':'hispanic_perc','college_pe':'college_perc','unemployed':'unemployed_perc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "holc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e85e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "holc_data_v2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce575b1",
   "metadata": {},
   "source": [
    "## 1.2 Data cleaning and exploration (10 pts)\n",
    "In addition to your .describe() descriptive statistics, in the following cells, create charts and/or maps that will tell us the following: \n",
    "- Define your characteristics of interest \n",
    "- What are the historical trends for each characteristic? \n",
    "\n",
    "Make sure to describe (Also, do all Census characteristics exist for all years??)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b790f",
   "metadata": {},
   "source": [
    "First, remove rows where the HOLC grade is 'E' in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d13fd2c",
   "metadata": {},
   "source": [
    "Next, create charts where 'year' is on the x-axis and the socioeconomic/demographic information is on the y axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed1d53",
   "metadata": {},
   "source": [
    "## 1.3 Predicting HOLC grade using socioeconomic and demographic data during redlining (10 pts)\n",
    "We believe that since HOLC grades are determinative of demographic and socioeconomic characteristics, we can back out grades by using some of these characteristics. Let's use some of these to predict HOLC grades. Here you will use the `holc_data` dataset. \n",
    "\n",
    "First, create `X` and `y` arrays contains our features and targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ef234",
   "metadata": {},
   "source": [
    "Do we have any `NaN`s? Our ML models will not accept missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f82afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f841f1",
   "metadata": {},
   "source": [
    "In order to assure we do not have any `NaNs` in our data, which , we'll replace all of our `NaN`s with the median of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea61bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68decfd3",
   "metadata": {},
   "source": [
    "We'll also want standardize our data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd565fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f84c3bc",
   "metadata": {},
   "source": [
    "Now let's split our data into a train and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb26733",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b57683",
   "metadata": {},
   "source": [
    "Using a `RandomForestClassifier` model, let's train our model to predict `y_train` on the input data `X_train` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b177613",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb2435",
   "metadata": {},
   "source": [
    "How well did our model do? Show the accuracy, F1, AUC ROC, log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6900275",
   "metadata": {},
   "source": [
    "Now try a different model and let's see if our results were better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0daf6e",
   "metadata": {},
   "source": [
    "Show the classification scores again for this new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581362ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba5e9c4",
   "metadata": {},
   "source": [
    "Since the scores weren't so different, let's go back to the RF Classifier model and tune its hyperparamters, so we can look at feature importances later. Please explain what you chose to tune. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd46d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb3f22",
   "metadata": {},
   "source": [
    "Now, how well did you prediction improve? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72804285",
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8198242b",
   "metadata": {},
   "source": [
    "## 1.4 Feature importances (3pts)\n",
    "Create a plot of the feature importances for each feature. You can use the sample code here: https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "\n",
    "- What seems to be most important features in determining outcomes? \n",
    "- Is this surprising? What did you expect to be more important? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390fc9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b9dd4",
   "metadata": {},
   "source": [
    "## 1.5 Predicting with pre-redlining data (10 pts)\n",
    "We're going to use the 1930s data and the change between 1930 and 1940, since we don't really have a lot of data for 1930.\n",
    "\n",
    "- How did the scores change? \n",
    "- What were the most important features and is this surprising? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84090a44",
   "metadata": {},
   "source": [
    "First, create the `population_1940_1930_diff`, `black_perc_1940_1930_diff`, `white_perc_1940_1930_diff` variables that show the change in these three between 1930 and 1940. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48da7b-95a4-4563-b52c-186d50e60e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f67ed6",
   "metadata": {},
   "source": [
    "Now run a classification model again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3db324",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed6cc4",
   "metadata": {},
   "source": [
    "And show how well the model did and whether the scores changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994860a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3bfd1c",
   "metadata": {},
   "source": [
    "And what are the feature importances? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ecef87-0a6e-4a49-bc1b-4b27e62a3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17914f",
   "metadata": {},
   "source": [
    "## Bonus: Feature creation (5 pts)\n",
    "Let's say we think that the distance to the center of the city matters in terms of what the grade might be. \n",
    "- Create a new column called `dist_center` that is the distance from the centroid of each neighborhood (row) to the centroid of all the rows for each `city`. \n",
    "- Include this new column in your model. \n",
    "- Did it improve your scores? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de2922-7939-42fb-96ad-c843dca304ba",
   "metadata": {},
   "source": [
    "# 2. Predicting NYC taxi pick-up and drop-offs (40 pts)\n",
    "In this exercise, we will be trying to predict where a taxi is being picked up based on where it's dropped off. \n",
    "\n",
    "That is: we want to predict the `PULocationID` using the rest of the data. \n",
    "\n",
    "This data is from: \n",
    "https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "\n",
    "- Please familiarize yourself with the data dictionary and the taxi zones. \n",
    "- Would it make sense to add more features by bringing in more data through, for ex, the census? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25c7ec-9ffa-4f79-bde1-b4897c546888",
   "metadata": {},
   "outputs": [],
   "source": [
    "### You will have to download the data from the link above\n",
    "### A parquet file is a file format that is very efficient for\n",
    "### storing dataframes. \n",
    "\n",
    "taxi_data = pd.read_parquet('yellow_tripdata_2024-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455aebf6-2dc4-4ac1-bf0e-fc4003641657",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc571d7ca67236538d190807671ab3198970b7d67f23d825ad141ff90f68066a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
