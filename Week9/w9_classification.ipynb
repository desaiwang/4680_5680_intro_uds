{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-gambling",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7a244",
   "metadata": {},
   "source": [
    "# Learning goals\n",
    "After today's lesson you should be able to:\n",
    "- Implement classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-introduction",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-power",
   "metadata": {},
   "source": [
    "# Predicting Income Categories\n",
    "We are going to use a dataset from the University of California Urvine's [Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). \n",
    "\n",
    "# 0. Data\n",
    "This is a dataset that has been extract from the 1994 Census and contains 48,842 observations. \n",
    "\n",
    "Here is the list of attributes: \n",
    "\n",
    "- income: >50K, <=50K.\n",
    "- age: continuous.\n",
    "- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- fnlwgt: continuous.\n",
    "- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- education-num: continuous.\n",
    "- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- sex: Female, Male.\n",
    "- capital-gain: continuous.\n",
    "- capital-loss: continuous.\n",
    "- hours-per-week: continuous.\n",
    "- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17628626",
   "metadata": {},
   "source": [
    "## 0.1 Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b832b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "data = pd.read_csv(url, header=None)\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ed271",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86639897",
   "metadata": {},
   "source": [
    "## 0.2 Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace the data coded \"?\" with NaN\n",
    "data = data.replace(' ?', np.nan)\n",
    "## Next, drop all rows with NaN\n",
    "data = data.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770dfc6",
   "metadata": {},
   "source": [
    "# 1. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b0187",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b3af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ee508",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(4,2))\n",
    "sns.countplot(data = data , y='income',hue = 'sex',palette='Set2',edgecolor=\".6\",ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef68644",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(12,6))\n",
    "sns.countplot(data = data , y='occupation',hue = 'income',palette='Set2',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c2dbb6",
   "metadata": {},
   "source": [
    "Note that we can also make these vertical bar charts, but I think charts the horizontal ones look better because of the text is not squeezed on the y-axis in teh case of many categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(12,6))\n",
    "\n",
    "sns.countplot(data = data , x='occupation',hue = 'income',palette='Set2',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(12,6))\n",
    "sns.countplot(data = data , y='occupation',hue = 'income',palette='Set2',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(12,6))\n",
    "sns.countplot(data = data , y='race',hue = 'income',palette='Set2',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41546576",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']].hist(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52d6f4",
   "metadata": {},
   "source": [
    "# 2. Prep data for training\n",
    "\n",
    "## 2.1 Encode categorical variables to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new dataframe with only the numerical data\n",
    "data_num = data[['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in machine learning, we often want to convert categorical variables to numerical dummy variables \n",
    "# Convert categorical variables to numerical\n",
    "categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']\n",
    "dummy_df_list = []\n",
    "for col in categorical_cols:\n",
    "    dummy_df = pd.get_dummies(data[col], prefix=col)\n",
    "    dummy_df_list.append(dummy_df)\n",
    "\n",
    "data_dummy = pd.concat(dummy_df_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787d782-be54-4031-87a8-3a7bc61bdc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = pd.concat([data_num, data_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We are going to set all the non-income columns as X\n",
    "X = data_new[data_new.columns.difference(['income_ >50K', 'income_ <=50K'])]\n",
    "y = data_new['income_ >50K']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec46f2f",
   "metadata": {},
   "source": [
    "## 2.2 Create a training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ff5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c2f7f",
   "metadata": {},
   "source": [
    "# 3. Modeling\n",
    "\n",
    "## 3.1 Model using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0872d5",
   "metadata": {},
   "source": [
    "Model using our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762be86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## We can use %%time to see how long it takes to run the code\n",
    "## %% are called magic functions in Jupyter Notebook\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "## Train the model on the training data\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca41a9f2",
   "metadata": {},
   "source": [
    "Get the prediction for the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b712a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5801f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0471d49e",
   "metadata": {},
   "source": [
    "Alternatively, we can use the score method to get the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35853b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bd8c0e",
   "metadata": {},
   "source": [
    "Let's also take a look at the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a27bf",
   "metadata": {},
   "source": [
    "Divide by the total number to get percentages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d593bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d192b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bfc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have a {cm[0][0]*100:.{2}}% true negative rate and a {cm[1][1]*100:.{2}}% % true positive rate.\\n We have a {cm[1][0]*100:.{2}}% false negative rate and a {cm[0][1]*100:.{2}}% false positive rate. \\n Note that our upper-right and lower-left (TP, TN) sum to the accuracy score. \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07d6898",
   "metadata": {},
   "source": [
    "## 3.2 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## SVC() is a support vector classifier \n",
    "## There is also a support vector regressor SVR()\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a140767",
   "metadata": {},
   "source": [
    "Notice that took a lot longer to run than the Naive Bayes! And the model performed slightly worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd48893",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f4afa",
   "metadata": {},
   "source": [
    "We also have a higher false negative rate, too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a44544",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2577cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have a {cm[0][0]*100:.{2}}% true negative rate and a {cm[1][1]*100:.{2}}% % true positive rate.\\n We have a {cm[1][0]*100:.{2}}% false negative rate and a {cm[0][1]*100:.{2}}% false positive rate. \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a955e",
   "metadata": {},
   "source": [
    "## 3.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a713097",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e71d85e",
   "metadata": {},
   "source": [
    "## 3.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b59fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6414145",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8861f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b8f68d",
   "metadata": {},
   "source": [
    "Faster than the support vector machine and with better accuracy and false negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f86b1b",
   "metadata": {},
   "source": [
    "## 3.5 Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610918c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa49799",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c9d679",
   "metadata": {},
   "source": [
    "Even better. This will not always be the case. However, ensemble learning methods very often outperform other types of machine learning models because they combine multiple models to make more accurate predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b59da",
   "metadata": {},
   "source": [
    "# Q.1\n",
    "- Using this same dataset, try to predict to predict gender based on other categories. Which model performed the best and by what metrics (time? accuracy? false predictions?) did you determine this.\n",
    "- Instead of a 66/33 split, try a 80/20 split on your best performing model. Did this improve your model performance?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
